\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage[english]{isodate}
\usepackage[noend]{algorithmic}
\usepackage{algorithm}
\usepackage[T2A]{fontenc}
\usepackage{url}
\usepackage{fancyref}

\begin{document}

\begin{center}
    \Large \bf Групповой проект по курсу <<Системы разработки данных и машинного обучения>>
\end{center}

\begin{flushleft}
    \begin{tabular}[H]{ll}
        Выполнили: & Бажанов Константин, 471 ПМИ\\
        &Егурнов Александр, 471 ПМИ\\
        &Зрянина Мария, 471 ПМИ\\
    \end{tabular}
\end{flushleft}

В рамках работы рассматривается применение трёх различных методов построения дерева решения для задачи бинарной классификации.\\\\
Отчет устроен следующим образом. В Секции \ref{sec:data} описываются данные и приводятся результаты применения нескольких алгоритмов бинарной классификации.
В Секции \ref{sec:randomforest} приводится описание алгоритма {\it Random Forest} и результаты его применения на данных.
В Секции \ref{sec:sashaegurnov} приводится описание алгоритма {\it НАЗВАНИЕ САШИНОГО АЛГОРИТМА} и результаты его применения на данных.
В Секции \ref{sec:mashazryanina} приводится описание алгоритма {\it НАЗВАНИЕ МАШИНОГО АЛГОРИТМА} и результаты его применения.
В Секции \ref{sec:conclusion} проводится сравнение трёх приведенных алгоритмов.

\section{Данные}
\label{sec:data}

В качестве данных для анализа был выбран набор {\it <<Census Income>>} \cite{Kohavi+Becker:1996}.
Данные садержат информацию о возрасте, образвании, семейном положении, текущей профессии, рассе и поле, а так же стране в которой селовек родился.
Всего 14 признаков описывает каждого человека, причем 6 из них непрерывные, а оставшиеся 8 являются дискретными.
В наборе имеется 48842 записи, однако, в некоторых из них могут отсутствовать значения признаков, поэтому было принято решение избывиться от таких записей.
В результате осталось 45222 записи, 30162 из них выделены в обучающую выборку, а 15060 в тестовую.
По данным признакам необходимо научиться предсказывать заработок человека, а именно, закабытывает ли он более 50000\$ в год или нет.\\

Так же известны результаты применения нескольких алгоритмов на приведенных данных. С использованием алгоритма {\it Forward Sequential Selection} \cite{langley+sage} удалось достичь ошибки в 14,05\%, а с использованием {\it NBTree} \cite{kohavi} ошибки в 14,10\%.

\section{Random Forest}
\label{sec:randomforest}

Метод {\it Random Forest} \cite{breiman} был предложен Лео Брейманом в 2001.\\

Пусть имеется обучающая выборка размера $N$, причем каждый объект из этой выборки описывается $M$ признаками.
Алгоритму на вход подается число $m < M$ и число $K$ -- количество деревьев, которые алгоритм будет строить.
Ниже приводится алгоритм построения одного дерева из $K$:
\begin{enumerate}
    \item Генерируем случайну выборку с повторением (аналогично генерации выборки в ботстреппинге) размера $N$.
    \item Строим дерево решений, при этом для каждой вершины выбираем случайным образом $m$ признаков из которых выбираем лучший.
    \item Дерево строится полность, прунинг не применяется
\end{enumerate}

Интересно отметить, что если выбрать $m=1$ то получается случайное дерево. Но как правило выбирают $m = \sqrt M$\\

Так же стоит отметить несколько достоинств данного метода:
\begin{enumerate}
    \item Не склонен к переобучению при росте $K$
    \item Легко параллизуется
    \item Одинаково хорошо работает как с непрерывными, так и с дискретными ризнаками
\end{enumerate}

\section{Саша Егурнов}
\label{sec:sashaegurnov}

\section{Маша Зрянина}
\label{sec:mashazryanina}

\section{Заключение}
\label{sec:conclusion}

\bibliographystyle{plain}
\bibliography{report}

\end{document}
